{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigate to the Correct Directory\n",
    "\n",
    "The following code navigates to the dataprocessing directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/google/home/carverforbes/activity-recognition/location/lbs/activity/audioset/dataprocessing\n"
     ]
    }
   ],
   "source": [
    "cd ../dataprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the import statements\n",
    "\n",
    "The following code imports the necessary code to run the code in the rest of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran the import statements.\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "import audio_processing as ap\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import sys\n",
    "from absl import logging\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# The following lines adjust the granularity of reporting.\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "# tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "print(\"Ran the import statements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logging to print logging.INFO logs\n",
    "logging.set_verbosity(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments for audio_processing\n",
    "src_dir = 'example_src_dir'\n",
    "dest_dir = 'example_dest_dir'\n",
    "filename = 'testset'\n",
    "labels = ['Gunshot, gunfire']\n",
    "available_features = ['chroma_stft',\n",
    "                       'chroma_cqt',\n",
    "                       'chroma_cens',\n",
    "                       'melspectrogram',\n",
    "                       'mfcc',\n",
    "                       'rms',\n",
    "                       'spectral_centroid',\n",
    "                       'spectral_bandwidth',\n",
    "                       'spectral_contrast',\n",
    "                       'spectral_flatness',\n",
    "                       'spectral_rolloff',\n",
    "                       'poly_features',\n",
    "                       'tonnetz',\n",
    "                       'zero_crossing_rate'\n",
    "]\n",
    "features_to_extract = ['rms']\n",
    "last_features = None\n",
    "redo = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_csv(dataframe, dest_path):\n",
    "    df = dataframe.copy()\n",
    "    for column in df.columns:   \n",
    "        for i in range(df[column].size):\n",
    "            if isinstance(df[column][i], np.ndarray):\n",
    "                df[column][i] = df[column][i].tolist()\n",
    "    df.to_csv(path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dataframe(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for column in df.columns:\n",
    "        for i in range(df[column].size):\n",
    "            if isinstance(df[column][i], str):\n",
    "                temp = df[column][i][1:-1]\n",
    "                temp = temp.replace(',', ' ').split(']')\n",
    "                new_list = []\n",
    "                for item in temp:\n",
    "                    if item == '':\n",
    "                        continue\n",
    "                    item = item.replace('[', '').strip().split()\n",
    "                    item = [float(num) for num in item]\n",
    "                    arr = np.array(item)\n",
    "                    new_list.append(arr)\n",
    "                new_arr = np.array(new_list)\n",
    "                df[column][i] = new_arr\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset as a pandas Dataframe object.\n",
    "csv_path = os.path.join(dest_dir, filename + '.csv')\n",
    "features_changed = last_features is None or features_to_extract != last_features\n",
    "last_features = features_to_extract\n",
    "if os.path.isfile(csv_path) and not True and not features_changed:\n",
    "    df = csv_to_dataframe(csv_path)\n",
    "else:\n",
    "    df = ap.output_df(src_dir, dest_dir, filename, labels, features_to_extract, redo)\n",
    "    dataframe_to_csv(df, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.024051616, 0.02332899, 0.023757856, 0.0242...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.018282544, 0.018028082, 0.017703537, 0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.04337968, 0.04965238, 0.052755404, 0.05585...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0066741644, 0.00669201, 0.0066719446, 0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                rms\n",
       "0      1  [[0.024051616, 0.02332899, 0.023757856, 0.0242...\n",
       "1      1  [[0.018282544, 0.018028082, 0.017703537, 0.016...\n",
       "2      1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "3      1  [[0.04337968, 0.04965238, 0.052755404, 0.05585...\n",
       "4      0  [[0.0066741644, 0.00669201, 0.0066719446, 0.00..."
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float32'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(len(df['rms'][4]))\n",
    "print(type(df['rms'][0]))\n",
    "print(type(df['rms'][0][0][0]))\n",
    "print(type(df['label'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-205-014a385941ca>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column][i] = new_arr\n"
     ]
    }
   ],
   "source": [
    "df_from_csv = csv_to_dataframe(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.024051615968346596, 0.0233289897441864, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.018282543867826462, 0.018028082326054573, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.04337967932224274, 0.049652379006147385, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0.006674164440482855, 0.006692009977996349, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                rms\n",
       "0      1  [[0.024051615968346596, 0.0233289897441864, 0....\n",
       "1      1  [[0.018282543867826462, 0.018028082326054573, ...\n",
       "2      1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "3      1  [[0.04337967932224274, 0.049652379006147385, 0...\n",
       "4      0  [[0.006674164440482855, 0.006692009977996349, ..."
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(len(df_from_csv['rms'][9]))\n",
    "print(type(df_from_csv['rms'][9]))\n",
    "print(type(df_from_csv['rms'][9][0][0]))\n",
    "print(type(df_from_csv['label'][9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>melspectrogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[3.4128592014312744, 2.5363638401031494, 2.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.009717190638184547, 0.002868133829906583, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.17820563912391663, 0.09990730881690979, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0009625130333006382, 0.0006070901872590184...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                     melspectrogram\n",
       "0      1  [[3.4128592014312744, 2.5363638401031494, 2.29...\n",
       "1      1  [[0.009717190638184547, 0.002868133829906583, ...\n",
       "2      1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "3      1  [[0.17820563912391663, 0.09990730881690979, 0....\n",
       "4      0  [[0.0009625130333006382, 0.0006070901872590184..."
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_rms = df_from_csv.copy()\n",
    "train_df_rms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>melspectrogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0.052792735397815704, 0.03404252976179123, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.4272644519805908, 0.3823623061180115, 0.67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1.435829520225525, 1.8679133653640747, 1.284...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.043675199151039124, 0.015942996367812157, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>[[3505.867431640625, 3847.041015625, 4128.8388...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                     melspectrogram\n",
       "6       0  [[0.052792735397815704, 0.03404252976179123, 0...\n",
       "26      1  [[0.4272644519805908, 0.3823623061180115, 0.67...\n",
       "9       1  [[1.435829520225525, 1.8679133653640747, 1.284...\n",
       "22      1  [[0.043675199151039124, 0.015942996367812157, ...\n",
       "23      0  [[3505.867431640625, 3847.041015625, 4128.8388..."
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_rms = train_df_rms.reindex(\n",
    "    np.random.permutation(train_df_rms.index))\n",
    "train_df_rms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'rms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-f2f371f1575e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(train_df_rms.rms[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df_rms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_df_rms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mrows_with_none\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'rms'"
     ]
    }
   ],
   "source": [
    "# temp bug fix for rows with None features\n",
    "# also deletes the outer array in the features\n",
    "rows_with_none = []\n",
    "print(train_df_rms.size / 2)\n",
    "# print(train_df_rms.rms[0])\n",
    "for i in train_df_rms.index:\n",
    "    if train_df_rms.rms[i] is None:\n",
    "        rows_with_none.append(i)\n",
    "        continue\n",
    "    train_df_rms.rms[i] = train_df_rms.rms[i][0]\n",
    "print(rows_with_none)\n",
    "train_df_rms = train_df_rms.drop(rows_with_none)\n",
    "train_df_rms.size / 2\n",
    "train_df_rms.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_df_rms.rms.tolist(), dtype=object)\n",
    "y = np.array(train_df_rms.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp bug fix for having different sized features\n",
    "temp_x = []\n",
    "temp_y = []\n",
    "count = 0\n",
    "for arr, label in zip(X, y):\n",
    "    if arr is None or len(arr) < 431:\n",
    "#         print('hey look at me', len(arr))\n",
    "        count += 1\n",
    "        continue\n",
    "    temp_x.append(arr)\n",
    "    temp_y.append(label)\n",
    "X = np.array(temp_x, dtype=object)\n",
    "y = np.array(temp_y)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_val)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to fix bug:\n",
    "# ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).\n",
    "# It worked!!!\n",
    "from keras import backend as K\n",
    "x_train = K.cast_to_floatx(x_train)\n",
    "y_train = K.cast_to_floatx(y_train)\n",
    "x_val = K.cast_to_floatx(x_val)\n",
    "y_val = K.cast_to_floatx(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the plotting function.\n",
    "def plot_curve(epochs, hist, list_of_metrics, path, filename, list_of_hyperparameters):\n",
    "    \"\"\"Plot a curve of one or more classification metrics vs. epoch and save it to path.\"\"\"  \n",
    "    # list_of_metrics should be one of the names shown in:\n",
    "    # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    for m in list_of_metrics:\n",
    "        x = hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    if not os.path.isdir(path):\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "        except OSError as error:\n",
    "            logging.error(error)\n",
    "            \n",
    "    path = os.path.join(path, filename)\n",
    "    \n",
    "    if not os.path.isdir(path):\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "        except OSError as error:\n",
    "            logging.error(error)\n",
    "        \n",
    "    list_of_hyperparameters_temp = [str(item) for item in list_of_hyperparameters]\n",
    "    list_of_metrics_temp = [item if isinstance(item, str) else str(item.name) for item in list_of_metrics]\n",
    "    filename = '_'.join(list_of_metrics_temp) + '_' + '_'.join(list_of_hyperparameters_temp)\n",
    "    path = os.path.join(path, filename + '.png')\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    \n",
    "    return plt\n",
    "\n",
    "\n",
    "print(\"Defined the plot_curve function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 0\n",
    "Deep Neural Network:\n",
    "* Input Layer: 431 nodes\n",
    "* Hidden Layer 1: 431 nodes\n",
    "* Ouput Layer: 1 node\n",
    "\n",
    "Hyper-parameters:\n",
    "* Loss Function: BinaryCrossEntropy\n",
    "* Activation Function: Relu\n",
    "* Optimizer Function: RMSprop\n",
    "* Learning Rate: 0.001 \n",
    "* Epochs: 100\n",
    "* Batch_Size: 25\n",
    "* Classification Threshold: 0.7\n",
    "* Regularization: L2\n",
    "* Regularization Lambda: 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions that create and train a model.\n",
    "def create_model(my_learning_rate, my_metrics):\n",
    "    \"\"\"Create and compile a simple classification model.\"\"\"\n",
    "    # Discard any pre-existing version of the model.\n",
    "    model = None\n",
    "\n",
    "    # Most simple tf.keras models are sequential.\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Add the input layer of 431 nodes\n",
    "    model.add(tf.keras.layers.Dense(units=431, input_shape=(431,)))\n",
    "              \n",
    "    # Implement L2 regularization in the first hidden layer.\n",
    "    model.add(tf.keras.layers.Dense(units=431, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.05),\n",
    "                                  name='Hidden1'))\n",
    "\n",
    "    # Funnel the regression value through a sigmoid function.\n",
    "    model.add(tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
    "                                  activation=tf.sigmoid,\n",
    "                                  name='Output'))\n",
    "\n",
    "    # Call the compile method to construct the layers into a model that\n",
    "    # TensorFlow can execute.  Notice that we're using a different loss\n",
    "    # function for classification than for regression.    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),                                                   \n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=my_metrics)\n",
    "\n",
    "    return model        \n",
    "              \n",
    "def train_model(model, features, label, epochs, label_name,\n",
    "                batch_size=None, my_validation_split=0.0,\n",
    "                validation_data=None, shuffle=True):\n",
    "    \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "    # The x parameter of tf.keras.Model.fit can be a list of arrays.\n",
    "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=shuffle, validation_data=validation_data)\n",
    "\n",
    "    # The list of epochs is stored separately from the rest of history.\n",
    "    epochs = history.epoch\n",
    "\n",
    "    # Isolate the classification metric for each epoch.\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    return epochs, hist  \n",
    "\n",
    "print(\"Defined the create_model and train_model functions.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 25\n",
    "classification_threshold = 0.70\n",
    "label_name = \"label\"\n",
    "\n",
    "list_of_hyperparameters = [learning_rate, epochs, batch_size,\n",
    "                           classification_threshold,\n",
    "                           label_name]\n",
    "\n",
    "# Here is the updated definition of METRICS:\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(\n",
    "          name='accuracy', threshold=classification_threshold),\n",
    "      tf.keras.metrics.Precision(\n",
    "          thresholds=classification_threshold, name='precision'),\n",
    "      tf.keras.metrics.Recall(\n",
    "          thresholds=classification_threshold, name=\"recall\"),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, METRICS)\n",
    "\n",
    "my_model.summary()\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, x_train, y_train, epochs, \n",
    "                          label_name, batch_size, validation_data=(x_val, y_val))\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "list_of_metrics_to_plot = ['accuracy', \"precision\", \"recall\", 'val_accuracy', 'val_precision', 'val_recall'] \n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot, 'example_dest_dir/training_rms_dnn/', filename, list_of_hyperparameters)\n",
    "plot_curve(epochs, hist, ['loss', 'val_loss'], 'example_dest_dir/training_rms_dnn/', filename, list_of_hyperparameters)\n",
    "\n",
    "training_performance =  my_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Training Performance')\n",
    "print('---------------------------------')\n",
    "print('loss: ', training_performance[0])\n",
    "print('accuracy: ', training_performance[1])\n",
    "print('precision: ', training_performance[2])\n",
    "print('recall: ', training_performance[3])\n",
    "print()\n",
    "\n",
    "validation_performance =  my_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Validation Performance')\n",
    "print('---------------------------------')\n",
    "print('loss: ', validation_performance[0])\n",
    "print('accuracy: ', validation_performance[1])\n",
    "print('precision: ', validation_performance[2])\n",
    "print('recall: ', validation_performance[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 1\n",
    "Deep Neural Network:\n",
    "* Input Layer: 431 nodes\n",
    "* Hidden Layer 1: 431 nodes\n",
    "* Hidden Layer 2: 40 nodes\n",
    "* Ouput Layer: 1 node\n",
    "\n",
    "Hyper-parameters:\n",
    "* Loss Function: BinaryCrossEntropy\n",
    "* Activation Function: Relu\n",
    "* Optimizer Function: RMSprop\n",
    "* Learning Rate: 0.001 \n",
    "* Epochs: 250\n",
    "* Batch_Size: 25\n",
    "* Classification Threshold: 0.7\n",
    "* Regularization: L2\n",
    "* Regularization Lambda: 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions that create and train a model.\n",
    "def create_model(my_learning_rate, my_metrics):\n",
    "    \"\"\"Create and compile a simple classification model.\"\"\"\n",
    "    # Discard any pre-existing version of the model.\n",
    "    model = None\n",
    "\n",
    "    # Most simple tf.keras models are sequential.\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Add the input layer of 431 nodes\n",
    "    model.add(tf.keras.layers.Dense(units=431, input_shape=(431,)))\n",
    "              \n",
    "    # Implement L2 regularization in the first hidden layer.\n",
    "    model.add(tf.keras.layers.Dense(units=431, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.05),\n",
    "                                  name='Hidden1'))\n",
    "    \n",
    "    # Implement L2 regularization in the second hidden layer.\n",
    "    model.add(tf.keras.layers.Dense(units=40, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.05),\n",
    "                                  name='Hidden2'))\n",
    "\n",
    "    # Funnel the regression value through a sigmoid function.\n",
    "    model.add(tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
    "                                  activation=tf.sigmoid,\n",
    "                                  name='Output'))\n",
    "\n",
    "    # Call the compile method to construct the layers into a model that\n",
    "    # TensorFlow can execute.  Notice that we're using a different loss\n",
    "    # function for classification than for regression.    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),                                                   \n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=my_metrics)\n",
    "\n",
    "    return model        \n",
    "              \n",
    "def train_model(model, features, label, epochs, label_name,\n",
    "                batch_size=None, my_validation_split=0.1,\n",
    "                validation_data=None, shuffle=True):\n",
    "    \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "    # The x parameter of tf.keras.Model.fit can be a list of arrays.\n",
    "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=shuffle, validation_data=validation_data)\n",
    "\n",
    "    # The list of epochs is stored separately from the rest of history.\n",
    "    epochs = history.epoch\n",
    "\n",
    "    # Isolate the classification metric for each epoch.\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    return epochs, hist  \n",
    "\n",
    "print(\"Defined the create_model and train_model functions.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.001\n",
    "epochs = 250\n",
    "batch_size = 25\n",
    "classification_threshold = 0.70\n",
    "label_name = \"label\"\n",
    "\n",
    "list_of_hyperparameters = [learning_rate, epochs, batch_size,\n",
    "                           classification_threshold,\n",
    "                           label_name]\n",
    "\n",
    "# Here is the updated definition of METRICS:\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(\n",
    "          name='accuracy', threshold=classification_threshold),\n",
    "      tf.keras.metrics.Precision(\n",
    "          thresholds=classification_threshold, name='precision'),\n",
    "      tf.keras.metrics.Recall(\n",
    "          thresholds=classification_threshold, name=\"recall\"),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, METRICS)\n",
    "\n",
    "my_model.summary()\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, x_train, y_train, epochs, \n",
    "                          label_name, batch_size, validation_data=(x_val, y_val))\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "list_of_metrics_to_plot = ['accuracy', \"precision\", \"recall\", 'val_accuracy', 'val_precision', 'val_recall'] \n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot, 'example_dest_dir/training_rms_dnn/', filename, list_of_hyperparameters)\n",
    "plot_curve(epochs, hist, ['loss', 'val_loss'], 'example_dest_dir/training_rms_dnn/', filename, list_of_hyperparameters)\n",
    "\n",
    "training_performance =  my_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Training Performance')\n",
    "print('---------------------------------')\n",
    "print('loss: ', training_performance[0])\n",
    "print('accuracy: ', training_performance[1])\n",
    "print('precision: ', training_performance[2])\n",
    "print('recall: ', training_performance[3])\n",
    "print()\n",
    "\n",
    "validation_performance =  my_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Validation Performance')\n",
    "print('---------------------------------')\n",
    "print('loss: ', validation_performance[0])\n",
    "print('accuracy: ', validation_performance[1])\n",
    "print('precision: ', validation_performance[2])\n",
    "print('recall: ', validation_performance[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 2\n",
    "Deep Neural Network:\n",
    "* Input Layer: 431 nodes\n",
    "* Hidden Layer 1: 431 nodes\n",
    "* Hidden Layer 2: 40 nodes\n",
    "* Hidden Layer 3: 20 nodes\n",
    "* Ouput Layer: 1 node\n",
    "\n",
    "Hyper-parameters:\n",
    "* Loss Function: BinaryCrossEntropy\n",
    "* Activation Function: Relu\n",
    "* Optimizer Function: RMSprop\n",
    "* Learning Rate: 0.001 \n",
    "* Epochs: 200\n",
    "* Batch_Size: 25\n",
    "* Classification Threshold: 0.7\n",
    "* Regularization: L2\n",
    "* Regularization Lambda: 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions that create and train a model.\n",
    "def create_model(my_learning_rate, my_metrics):\n",
    "    \"\"\"Create and compile a simple classification model.\"\"\"\n",
    "    # Discard any pre-existing version of the model.\n",
    "    model = None\n",
    "\n",
    "    # Most simple tf.keras models are sequential.\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Add the input layer of 431 nodes\n",
    "    model.add(tf.keras.layers.Dense(units=431, input_shape=(431,)))\n",
    "              \n",
    "    # Implement L2 regularization in the first hidden layer.\n",
    "    model.add(tf.keras.layers.Dense(units=431, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.05),\n",
    "                                  name='Hidden1'))\n",
    "    \n",
    "    # Implement L2 regularization in the second hidden layer.\n",
    "    model.add(tf.keras.layers.Dense(units=40, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.05),\n",
    "                                  name='Hidden2'))\n",
    "    \n",
    "    # Implement L2 regularization in the third hidden layer.\n",
    "    model.add(tf.keras.layers.Dense(units=20, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.05),\n",
    "                                  name='Hidden3'))\n",
    "\n",
    "    # Funnel the regression value through a sigmoid function.\n",
    "    model.add(tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
    "                                  activation=tf.sigmoid,\n",
    "                                  name='Output'))\n",
    "\n",
    "    # Call the compile method to construct the layers into a model that\n",
    "    # TensorFlow can execute.  Notice that we're using a different loss\n",
    "    # function for classification than for regression.    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),                                                   \n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=my_metrics)\n",
    "\n",
    "    return model        \n",
    "              \n",
    "def train_model(model, features, label, epochs, label_name,\n",
    "                batch_size=None, my_validation_split=0.1,\n",
    "                validation_data=None, shuffle=True):\n",
    "    \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "    # The x parameter of tf.keras.Model.fit can be a list of arrays.\n",
    "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=shuffle, validation_data=validation_data)\n",
    "\n",
    "    # The list of epochs is stored separately from the rest of history.\n",
    "    epochs = history.epoch\n",
    "\n",
    "    # Isolate the classification metric for each epoch.\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    return epochs, hist  \n",
    "\n",
    "print(\"Defined the create_model and train_model functions.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.002\n",
    "epochs = 200\n",
    "batch_size = 50\n",
    "classification_threshold = 0.70\n",
    "label_name = \"label\"\n",
    "\n",
    "list_of_hyperparameters = [learning_rate, epochs, batch_size,\n",
    "                           classification_threshold,\n",
    "                           label_name]\n",
    "\n",
    "# Here is the updated definition of METRICS:\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(\n",
    "          name='accuracy', threshold=classification_threshold),\n",
    "      tf.keras.metrics.Precision(\n",
    "          thresholds=classification_threshold, name='precision'),\n",
    "      tf.keras.metrics.Recall(\n",
    "          thresholds=classification_threshold, name=\"recall\"),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, METRICS)\n",
    "\n",
    "# Print the models structure\n",
    "my_model.summary()\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, x_train, y_train, epochs, \n",
    "                          label_name, batch_size, validation_data=(x_val, y_val))\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "list_of_metrics_to_plot = ['accuracy', \"precision\", \"recall\", 'val_accuracy', 'val_precision', 'val_recall'] \n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot, 'example_dest_dir/training_rms_dnn/', filename, list_of_hyperparameters)\n",
    "plot_curve(epochs, hist, ['loss', 'val_loss'], 'example_dest_dir/training_rms_dnn/', filename, list_of_hyperparameters)\n",
    "\n",
    "training_performance =  my_model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Training Performance')\n",
    "print('---------------------------------')\n",
    "print('loss: ', training_performance[0])\n",
    "print('accuracy: ', training_performance[1])\n",
    "print('precision: ', training_performance[2])\n",
    "print('recall: ', training_performance[3])\n",
    "print()\n",
    "\n",
    "validation_performance =  my_model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Validation Performance')\n",
    "print('---------------------------------')\n",
    "print('loss: ', validation_performance[0])\n",
    "print('accuracy: ', validation_performance[1])\n",
    "print('precision: ', validation_performance[2])\n",
    "print('recall: ', validation_performance[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
